\documentclass{cours}
\setlength{\headheight}{30pt}

\title{Succession d'Épreuves Indépendantes \\ Loi Binomiale}

\begin{document}
    \maketitle{9}

    \begin{Gpartie}{Succession d'Épreuves Indépendantes} 
        \begin{Spartie}{Rappel} 
            Deux épreuves successives sont indépendantes lorsque le résultat de la première n'influe pas sur le résultat de la deuxième.

            \begin{center}
                % \begin{tikzpicture}
                    \includegraphics[width=10cm]{example-image}
                % \end{tikzpicture}
                \parbox{\linewidth}{\captionof{figure}{Arbre de Probabilité qui Présente l'Indépendance des Épreuves}} \\[2ex]
            \end{center}
            Ainsi, $A$ et $B$ sont deux événements indépendants si et seulement si :
            \begin{itemize}
                \item $P_A(B)=P_{\overline{A}}(B)=P(B)$
                \item $P(A\cap B)=P(A)\times P(B)$
            \end{itemize}
        \end{Spartie}
        \pagebreak
        \begin{Spartie}{Modélisations} 
            On peut représenter une succession de $n$ épreuves indépendantes par un arbre pondéré (une issue de cette succession d'épreuves est alors un chemin sur l'arbre).

            Si les $n$ épreuves indépendantes ont pour univers respectifs $\Omega_1\,,\Omega_2\,,\dotsb\,,\Omega_n$, les issues de ces $n$ épreuves sont les éléments du produit cartésien $\Omega_1\times\Omega_2\times\dotsb\times\Omega_n$.
        \end{Spartie}
        \begin{Spartie}{Exemple} 
            Un restaurant propose deux entrées $e_1$ et $e_2$, trois plats $p_1$, $p_2$, et $p_3$ et un dessert $d$.

            Un client prend au hasard une entrée, un plat, et un dessert.

            L'ensemble des issues de cette expérience est $\Omega=\Omega_1\times\Omega_2\times\Omega_3$ où $\Omega_1=\big\{e_1\,; e_2\big\},\ \Omega_2=\big\{p_1\,; p_2\,; p_3\big\},\text{ et }\Omega_3=\big\{d\big\}$

            Ainsi, $\Omega=\bigg\{\big(e_1\,, p_1\,, d\big)\,;\big(e_1\,, p_2\,, d\big)\,;\dotsc\bigg\}$

            On peut aussi représenter la situation par un arbre :
            \begin{center}
                % \begin{tikzpicture}
                    \includegraphics[width=10cm]{example-image}
                % \end{tikzpicture}
                \parbox{\linewidth}{\captionof{figure}{Arbre Pondéré Représentant la Situation}}
                \\[2ex]
            \end{center}
        \end{Spartie}
    \end{Gpartie}
    \pagebreak
    \begin{Gpartie}{Loi Binomiale} 
        \begin{Spartie}{Épreuve de Bernoulli} 
            \begin{SSpartie}{Définition} 
                Une épreuve de Bernoulli est un expérience aléatoire possédant deux issues qu'on appelle généralement ``succès'' et ``échec''. La probabilité du succès $p$ est appelée paramètre de la loi de Bernoulli.
                \begin{center}
                    \begin{tabular}{  | p{0.1\textwidth} || *{2}{w{c}{0.1\textwidth} | }  } \hline
                        $k_i$           & $0$ & $1$ \\ \hline
                        $P(X=k_i)$      &$1-p$& $p$ \\ \hline
                    \end{tabular}
                    \parbox{\linewidth}{\captionof{figure}{Loi de la Variable Aléatoire X}}
                \end{center}
                $X$ est une variable aléatoire donnant le nombre de succès (il n'y a que deux possibilités : 0 ou 1). On dit que $X$ suit la loi de Bernoulli. \\ Penser à un jeu de pile ou face.
            \end{SSpartie}
            \begin{SSpartie}{Propriété} 
                Si $X$ est une variable aléatoire suivant la loi de Bernoulli de paramètre $p$, alors, l'espérance de $X$ est $E(X)=p$ et sa variance est $V(X)=p(1-p)$.
            \end{SSpartie}
        \end{Spartie}
        \begin{Spartie}{Schéma de Bernoulli} 
            \begin{SSpartie}{Définition} 
                Un schéma de Bernoulli est une répétition de $n$ épreuves \emph{identiques} et \emph{indépendantes} à deux issues ($n$ épreuves de Bernoulli).

                Une issue de cette expérience aléatoire est un élément ($n$-uplet) de $\Omega=\big\{S\,;\overline{S}\big\}^n$.
            \end{SSpartie}
            \begin{SSpartie}{Exemple} 
                On tire successivement $4$ fois à pile ou face avec une pièce (truquée peut-être) dont la probabilité de tomber sur ``pile'' est $p$. 
                
                Les tirages obtenus sont des 4-uplets composés de $P$ et de $F$ (si l'on note $P$ l'événement ``tomber sur pile'' et $F$ ``tomber sur face'').
                
                Un exemple de tirage est $\big(P\,, F\,, F\,, F\big)$. On peut aussi noter $S$ et $\overline{S}$ au lieu de $P$ et $F$.
            \end{SSpartie}
        \end{Spartie}
        \pagebreak
        \begin{Spartie}{Loi Binomiale} 
            \begin{SSpartie}{Définition} 
                On considère une expérience aléatoire qui suit un schéma de Bernoulli, autrement dit, une répétition de $n$ épreuves \emph{identiques} et \emph{indépendantes} à deux issues (succès et échec) dont la probabilité de succès est $p$.

                La variable aléatoire donnant le nombre de succès suit la loi binomiale de paramètres $n$ et $p$, notée $\mathcal{B}(n\,, p)$. Cette loi est aussi parfois appelée loi du nombre de succès.
            \end{SSpartie}
            \begin{SSpartie}{Propriété} 
                Soit $X$ une variable aléatoire suivant la loi binomiale de paramètres $n$ et $p$, on peut aussi noter $X\sim\mathcal{B}(n\,, p)$.

                Pour tout entier $k$ compris entre $0$ et $n$ :
                \[P(X=k)=\binom{n}{k}p^k(1-p)^{n-k}\]

                \begin{center}
                    % \begin{tikzpicture}
                        \includegraphics[width=10cm]{example-image}
                    % \end{tikzpicture}
                    \parbox{\linewidth}{\captionof{figure}{Illustration de la Loi Binomiale}}
                \end{center}
                \pagebreak
                \begin{SSSpartie}{Démonstration} 
                    Dans l'arbre, chaque chemin contenant exactement $k$ succès passe par $k$ branches de probabilité $p$ et $n-k$ branches de probabilité $1-p$. Ainsi la probabilité d'un tel chemin est $p^k(1-p)^{n-k}$.

                    On compte ensuite le nombre de chemins contenant $k$ succès : il y en a $\binom{n}{k}$.

                    On peut aussi considérer qu'un tirage est un $n$-uplet contenant des $S$ et des $\overline{S}$.

                    Ainsi, un tirage contenant $k$ succès comporte $k$ fois la lettre $S$ et $n-k$ fois la lettre $\overline{S}$. Le nombre de façons de disposer les $k$ ``$S$'' parmi les $n$ éléments est $\binom{n}{k}$.
                \end{SSSpartie}
                \begin{SSSpartie}{Exemple} 
                    Avec nos $4$ tirages de pièce truquée, si on a $p=\frac{2}{3}$ (la probabilité de tirer ``pile'' est $\frac{2}{3}$) et si on note $X$ la variable aléatoire donnant le nombre de ``pile'', on a :
                    \[P\big(X=1\big)=\binom{4}{1}\Bigg(\frac{2}{3}\Bigg)^1\Bigg(1-\frac{2}{3}\Bigg)^{4-1}=4\times\Bigg(\frac{2}{3}\Bigg)\times\Bigg(\frac{1}{3}\Bigg)^3\approx 0{,}099\]
                \end{SSSpartie}
            \end{SSpartie}
            \begin{SSpartie}{Propriété} 
                Soit $X$ une variable aléatoire suivant la loi binomiale $\mathcal{B}(n\,, p)$.

                L'Espérance de $X$ est $E(X)=np$ \\ La variance de $X$ est $V(X)=np(1-p)$ \\ L'Écart-type de $X$ est $\sigma(X)=\sqrt{np(1-p)}$

                Démonstration dans chapitre sur les opérations sur les Variables Aléatoires.
                \begin{SSSpartie}{Exemple} 
                    On reprend la pièce truquée précédente, qu'on lance quatre fois. $X$ est toujours la variable aléatoire donnant le nombre de ``pile''.

                    $E(X)=4\times\frac{2}{3}\approx 2{,}67$\quad (On peut espérer d'obtenir 2{,}67 piles sur 4 tirages).

                    $\sigma(X)=\sqrt{4\times\frac{2}{3}\times\frac{1}{3}}\approx 0{,}94$\quad (Dont l'interprétation est moins intéressante).
                \end{SSSpartie}
            \end{SSpartie}
        \end{Spartie}
    \end{Gpartie}
\end{document}